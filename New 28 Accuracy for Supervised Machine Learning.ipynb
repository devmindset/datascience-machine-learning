{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94860813704496794"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    "y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_true,y_pred,labels=[\"cat\",\"ant\",\"bird\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121bf3678d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD7CAYAAAArZlyJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV0O4P8cdrmwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121bf372470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "sns.heatmap(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0],\n",
       "       [0, 2, 0],\n",
       "       [1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Understanding precision & recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function precision_score in module sklearn.metrics.classification:\n",
      "\n",
      "precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
      "    Compute the precision\n",
      "    \n",
      "    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
      "    true positives and ``fp`` the number of false positives. The precision is\n",
      "    intuitively the ability of the classifier not to label as positive a sample\n",
      "    that is negative.\n",
      "    \n",
      "    The best value is 1 and the worst value is 0.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : list, optional\n",
      "        The set of labels to include when ``average != 'binary'``, and their\n",
      "        order if ``average is None``. Labels present in the data can be\n",
      "        excluded, for example to calculate a multiclass average ignoring a\n",
      "        majority negative class, while labels not present in the data will\n",
      "        result in 0 components in a macro average. For multilabel targets,\n",
      "        labels are column indices. By default, all labels in ``y_true`` and\n",
      "        ``y_pred`` are used in sorted order.\n",
      "    \n",
      "        .. versionchanged:: 0.17\n",
      "           parameter *labels* improved for multiclass problem.\n",
      "    \n",
      "    pos_label : str or int, 1 by default\n",
      "        The class to report if ``average='binary'`` and the data is binary.\n",
      "        If the data are multiclass or multilabel, this will be ignored;\n",
      "        setting ``labels=[pos_label]`` and ``average != 'binary'`` will report\n",
      "        scores for that label only.\n",
      "    \n",
      "    average : string, [None, 'binary' (default), 'micro', 'macro', 'samples',                        'weighted']\n",
      "        This parameter is required for multiclass/multilabel targets.\n",
      "        If ``None``, the scores for each class are returned. Otherwise, this\n",
      "        determines the type of averaging performed on the data:\n",
      "    \n",
      "        ``'binary'``:\n",
      "            Only report results for the class specified by ``pos_label``.\n",
      "            This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "        ``'micro'``:\n",
      "            Calculate metrics globally by counting the total true positives,\n",
      "            false negatives and false positives.\n",
      "        ``'macro'``:\n",
      "            Calculate metrics for each label, and find their unweighted\n",
      "            mean.  This does not take label imbalance into account.\n",
      "        ``'weighted'``:\n",
      "            Calculate metrics for each label, and find their average, weighted\n",
      "            by support (the number of true instances for each label). This\n",
      "            alters 'macro' to account for label imbalance; it can result in an\n",
      "            F-score that is not between precision and recall.\n",
      "        ``'samples'``:\n",
      "            Calculate metrics for each instance, and find their average (only\n",
      "            meaningful for multilabel classification where this differs from\n",
      "            :func:`accuracy_score`).\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    precision : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "        Precision of the positive class in binary classification or weighted\n",
      "        average of the precision of each class for the multiclass task.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    >>> from sklearn.metrics import precision_score\n",
      "    >>> y_true = [0, 1, 2, 0, 1, 2]\n",
      "    >>> y_pred = [0, 2, 1, 0, 0, 1]\n",
      "    >>> precision_score(y_true, y_pred, average='macro')  # doctest: +ELLIPSIS\n",
      "    0.22...\n",
      "    >>> precision_score(y_true, y_pred, average='micro')  # doctest: +ELLIPSIS\n",
      "    0.33...\n",
      "    >>> precision_score(y_true, y_pred, average='weighted')\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    0.22...\n",
      "    >>> precision_score(y_true, y_pred, average=None)  # doctest: +ELLIPSIS\n",
      "    array([ 0.66...,  0.        ,  0.        ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = [1, 1, 2, 1, 1, 2]\n",
    "y_pred = [1, 2, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59999999999999998"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a computer program for recognizing dogs in photographs identifies eight dogs in a picture containing 12 dogs and some cats. Of the eight dogs identified, five actually are dogs (true positives), while the rest are cats (false positives). The program's precision is 5/8 while its recall is 5/12. When a search engine returns 30 pages only 20 of which were relevant while failing to return 40 additional relevant pages, its precision is 20/30 = 2/3 while its recall is 20/60 = 1/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
